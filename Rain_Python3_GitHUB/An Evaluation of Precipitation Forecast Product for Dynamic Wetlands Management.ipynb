{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Evaluation of Precipitation Forecast Product for Dynamic Wetlands Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast Model Data\n",
      "Forecast Products and Analyses\n",
      "Observation Data\n",
      "Radar Data\n",
      "Satellite Data\n",
      "Unidata case studies\n"
     ]
    }
   ],
   "source": [
    "from siphon.catalog import TDSCatalog\n",
    "top_cat = TDSCatalog('http://thredds.ucar.edu/thredds/catalog.xml')\n",
    "for ref in top_cat.catalog_refs:\n",
    "    print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pyproj\n",
    "from pyproj import Proj\n",
    "import os\n",
    "from scipy import interpolate\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "\n",
    "def to_datetime(date):\n",
    "    \"\"\"\n",
    "    Converts a numpy datetime64 object to a python datetime object \n",
    "    Input:\n",
    "      date - a np.datetime64 object\n",
    "    Output:\n",
    "      DATE - a python datetime object\n",
    "    \"\"\"\n",
    "    timestamp = ((date - np.datetime64('1970-01-01T00:00:00'))\n",
    "                 / np.timedelta64(1, 's'))\n",
    "    return datetime.utcfromtimestamp(timestamp)\n",
    "\n",
    "ds = xr.open_dataset('TIGGE/201207_PerturbedAll.grib', engine=\"cfgrib\")\n",
    "\n",
    "#separate variables\n",
    "lon = np.asarray(ds['longitude'])\n",
    "lat = np.asarray(ds['latitude'])\n",
    "time = np.asarray(ds['time'])\n",
    "data = ds['tp']\n",
    "EnsNumber = ds['number']\n",
    "LeadTimes = ds['step']\n",
    "\n",
    "#  # Convert the number of hours since the reference time to an actual date, check the array index\n",
    "#     time_val = num2date(time_var[timeId].squeeze(), time_var.units)\n",
    "#     print(num2date(time_var[timeId].squeeze(), time_var.units))\n",
    "\n",
    "#projection\n",
    "GRIB2_proj = Proj(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\") #put pm=-360 to indicate GRIB2 projection\n",
    "Projected = Proj(init=\"EPSG:26914\") #26914 Cypress UTM 14N\n",
    "\n",
    "#resample dx\n",
    "res = 1000.\n",
    "\n",
    "#convert coordinate\n",
    "x,y = np.meshgrid(lon, lat)\n",
    "UTMx, UTMy = pyproj.transform(GRIB2_proj, Projected, x.flatten(), y.flatten())\n",
    "UTMx_grid = np.reshape(UTMx,(x.shape))\n",
    "UTMy_grid = np.reshape(UTMy,(y.shape))\n",
    "xmin, xmax, ymin, ymax = [UTMx.min(), UTMx.max(), UTMy.min(), UTMy.max()]\n",
    "UTMx_res = np.arange(xmin, xmax, res)\n",
    "UTMy_res = np.arange(ymin, ymax, res)\n",
    "grid_x_res, grid_y_res = np.meshgrid(UTMx_res, UTMy_res)\n",
    "nrows_res, ncols_res = np.shape(grid_x_res)\n",
    "\n",
    "#select variables : 'tp' (number: 20, time: 124, step: 9, latitude: 7, longitude: 5)\n",
    "LeadTime = 0\n",
    "EnsMember = 0\n",
    "t = 0\n",
    "\n",
    "\n",
    "save_dir = 'Precipitation_Cypress_GEFS/'\n",
    "# save_dir_asc = save_dir + dirASC\n",
    "\n",
    "for EnsMember in range(EnsNumber.size):\n",
    "    #create folder for outputs files\n",
    "    for LeadTime in range(LeadTimes.size):\n",
    "        save_dir1 = save_dir + str(EnsMember) + '/' + str(LeadTime) + '/'\n",
    "        if not os.path.isdir(save_dir1):\n",
    "            os.makedirs(save_dir1)\n",
    "        \n",
    "        for t in range(time.size):\n",
    "            ds_subset_date = to_datetime(time[t])\n",
    "            ds_datetime = ds_subset_date.strftime(\"%Y%m%d%H\")\n",
    "            filenameASC = save_dir1 + 'GEFS.ens'+ str(EnsMember) + '.f' + str(LeadTime)+ '.' + ds_datetime + '.asc'\n",
    "\n",
    "            Precipitation_vals = np.asarray(data[dict(number=EnsMember, step=LeadTime, time=t)])\n",
    "            Precipitation_res = interpolate.griddata((UTMx_grid.flatten(), UTMy_grid.flatten()), Precipitation_vals.flatten(), (grid_x_res, grid_y_res) , method='cubic')\n",
    "            Precipitation_res[np.isnan(Precipitation_res)] = -9999\n",
    "\n",
    "            #save resampled raster to ascii\n",
    "            transform = from_origin(grid_x_res.min(), grid_y_res.max(), res, res)\n",
    "            new_dataset = rasterio.open(filenameASC, 'w', nodata = -9999, driver='AAIGrid', decimal_precision=1,\n",
    "                                        height = nrows_res, width = ncols_res,\n",
    "                                        count=1, dtype=str(Precipitation_res.dtype),\n",
    "                                        transform=transform,\n",
    "                                        crs=Projected.srs)\n",
    "            new_dataset.write(Precipitation_res, 1)\n",
    "            new_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GEFS to DSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to DSS\n",
    "import re\n",
    "import os\n",
    "import glob \n",
    "import platform\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# # Local variables:\n",
    "# my_path = os.path.abspath(os.path.dirname(__file__))\n",
    "# inDir = os.path.join(my_path, \"..\\PrecForecast\\GFS\\ASCII\")\n",
    "# openBATfile = my_path  + \"\\Batch_ASCIIToDSS.bat\"\n",
    "\n",
    "# Local variables:\n",
    "#inDir = 'Precipitation_Mongolia/ASC_2000_Dis/'\n",
    "save_dir = 'Precipitation_Cypress_GEFS/'\n",
    "\n",
    "\n",
    "for EnsMember in range(0, 20): \n",
    "    for LeadTime in range(2, 6):\n",
    "    #LeadTime = 3\n",
    "        save_dir1 = save_dir + str(EnsMember) + '/' + str(LeadTime) + '/'\n",
    "        openBATfile = save_dir1 + 'ASCIIToDSS.bat'\n",
    "        DSSNAME = \"GEFS-Ens-\" + str(EnsMember) + \"-f-\" + str(LeadTime)\n",
    "        # for generating asc2dss strings\n",
    "        text_1 = \"asc2dssGrid INPUT=\"\n",
    "        text_2 = \" DSS=\" + DSSNAME + \".dss PATH=/UTM14/Cypress/Precip/\"\n",
    "        text_3 = \"/\"\n",
    "        text_4 = \"/PROJECTED/ GRIDTYPE=UTM ZONE=14N DUNITS=mm DTYPE=PER-CUM\" \n",
    "\n",
    "        # Open and Write to file1  \n",
    "        file1 = open(openBATfile,\"w\")\n",
    "\n",
    "        date = [date for file in glob.glob(save_dir1+'*.asc') for date in re.findall(\"(\\d{10})\", file)]\n",
    "        date.sort(key = lambda date: datetime.strptime(date, \"%Y%m%d%H\")) \n",
    "        delt = datetime.strptime(date[1], \"%Y%m%d%H\") - datetime.strptime(date[0], \"%Y%m%d%H\")\n",
    "\n",
    "        AscFiles = glob.glob(save_dir1+'*.asc')\n",
    "\n",
    "\n",
    "        for index in range(0, len(date)):\n",
    "        # +'gefs.1deg.ens.'+ str(EnsMember)+ '.' + time_val.strftime(\"%Y%m%d%H\") + '.asc'\n",
    "            namefile = 'GEFS.ens'+ str(EnsMember) + '.' + 'f' + str(LeadTime) + '.' +date[index] + '.asc'\n",
    "            objDate = datetime.strptime(date[index], '%Y%m%d%H')\n",
    "\n",
    "            if (objDate.hour==0): \n",
    "                objDate0 = objDate - delt #timedelta(hours=1)\n",
    "                objDate = objDate - delt #timedelta(days=1)\n",
    "                converted_date = datetime.strftime(objDate,'%d%b%Y:2400') #HEC-DSS only accept 24:00 format!\n",
    "            else:\n",
    "                converted_date = datetime.strftime(objDate,'%d%b%Y:%H%M')\n",
    "                objDate0 = objDate - delt#timedelta(hours=1)\n",
    "\n",
    "            converted_date0 = datetime.strftime(objDate0,'%d%b%Y:%H%M')\n",
    "\n",
    "            full_text = text_1 + namefile + text_2 + converted_date0 + text_3 + converted_date + text_4\n",
    "            file1.write(full_text + \"\\n\")\n",
    "        \n",
    "        \n",
    "        file1.close() #to close file   \n",
    "        \n",
    "        os.chdir(save_dir1)\n",
    "        # convert asc to DSS\n",
    "        os.startfile('ASCIIToDSS.bat')\n",
    "#         # Move DSS files to HEC-HMS Working directory\n",
    "#         shutil.copytree(src, dst)\n",
    "        os.chdir('C:\\\\temp\\\\Flood_Forecasting')\n",
    "        #os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move DSS files to HEC-HMS Working directory\n",
    "import shutil\n",
    "import glob, os\n",
    "\n",
    "src = 'C:\\\\temp\\\\Flood_Forecasting\\\\Precipitation_Cypress_GEFS_2012'\n",
    "dst = 'C:\\\\temp\\\\Flood_Forecasting\\\\CypressHMS1\\\\Cypress_2012\\\\forecast'\n",
    "os.chdir(src)\n",
    "\n",
    "for root, dirs, files in os.walk(src):\n",
    "    for file in files:\n",
    "        if file.endswith(\".dss\"):\n",
    "            src_temp = os.path.join(root, file)\n",
    "            shutil.copy(src_temp, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSWEP Precipitation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset\n",
    "mswep = xr.open_dataset('Precipitation_MSWEP/201207.nc')\n",
    "time = np.asarray(mswep['time'])\n",
    "\n",
    "#projection\n",
    "GRIB2_proj = Proj(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\") #put pm=-360 to indicate GRIB2 projection\n",
    "Projected = Proj(init=\"EPSG:26914\") #26914 Cypress UTM 14N\n",
    "\n",
    "#resample dx\n",
    "res = 1000.\n",
    "\n",
    "# subset dataset\n",
    "West = -97\n",
    "East = -93.5\n",
    "North = 31.5\n",
    "South = 29.5\n",
    "Precipitation_mswep = mswep.sel(lon=[West, East], lat=[South, North], method='nearest').to_array()[0]\n",
    "lon=Precipitation_mswep['lon']\n",
    "lat=Precipitation_mswep['lat']\n",
    "\n",
    "#convert coordinate\n",
    "x,y = np.meshgrid(lon, lat)\n",
    "UTMx, UTMy = pyproj.transform(GRIB2_proj, Projected, x.flatten(), y.flatten())\n",
    "UTMx_grid = np.reshape(UTMx,(x.shape))\n",
    "UTMy_grid = np.reshape(UTMy,(y.shape))\n",
    "xmin, xmax, ymin, ymax = [UTMx.min(), UTMx.max(), UTMy.min(), UTMy.max()]\n",
    "UTMx_res = np.arange(xmin, xmax, res)\n",
    "UTMy_res = np.arange(ymin, ymax, res)\n",
    "grid_x_res, grid_y_res = np.meshgrid(UTMx_res, UTMy_res)\n",
    "nrows_res, ncols_res = np.shape(grid_x_res)\n",
    "\n",
    "\n",
    "save_dir = 'Precipitation_Cypress_MSWEP/'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "    \n",
    "# loop through time\n",
    "for t in range(time.size):\n",
    "    ds_subset_date = to_datetime(time[t])\n",
    "    ds_datetime = ds_subset_date.strftime(\"%Y%m%d%H\")\n",
    "    filenameASC = save_dir + 'MSWEP' + '.' + ds_datetime + '.asc'\n",
    "    \n",
    "    Precipitation_vals = np.asarray(Precipitation_mswep[:,:,t])  \n",
    "    Precipitation_res = interpolate.griddata((UTMx_grid.flatten(), UTMy_grid.flatten()), \n",
    "                                             Precipitation_vals.flatten(), (grid_x_res, grid_y_res), \n",
    "                                             method='cubic')\n",
    "    Precipitation_res[np.isnan(Precipitation_res)] = -9999\n",
    "\n",
    "    #save resampled raster to ascii\n",
    "    transform = from_origin(grid_x_res.min(), grid_y_res.max(), res, res)\n",
    "    new_dataset = rasterio.open(filenameASC, 'w', nodata = -9999, driver='AAIGrid', decimal_precision=1,\n",
    "                                height = nrows_res, width = ncols_res,\n",
    "                                count=1, dtype=str(Precipitation_res.dtype),\n",
    "                                transform=transform,\n",
    "                                crs=Projected.srs)\n",
    "    new_dataset.write(Precipitation_res, 1)\n",
    "    new_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MSWEPv1 to DSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to DSS\n",
    "import re\n",
    "import glob \n",
    "import platform\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Local variables:\n",
    "# my_path = os.path.abspath(os.path.dirname(__file__))\n",
    "# inDir = os.path.join(my_path, \"..\\Forecast_GFS\")\n",
    "# openBATfile = my_path  + \"\\ASCIIToDSS.bat\"\n",
    "\n",
    "# Local variables:\n",
    "#inDir = 'Precipitation_Mongolia/ASC_2000_Dis/'\n",
    "save_dir = 'Precipitation_Cypress_MSWEP/'\n",
    "openBATfile = save_dir + 'ASCIIToDSS.bat'\n",
    "\n",
    "# for generating asc2dss strings\n",
    "text_1 = \"asc2dssGrid INPUT=\"\n",
    "text_2 = \" DSS=MSWEP.dss PATH=/UTM14/Cypress/Precip/\"\n",
    "text_3 = \"/\"\n",
    "text_4 = \"/PROJECTED/ GRIDTYPE=UTM ZONE=14N DUNITS=mm DTYPE=PER-CUM\" \n",
    "\n",
    "# Open and Write to file1  \n",
    "file1 = open(openBATfile,\"w\")\n",
    "\n",
    "# date = [date for file in glob.glob(inDir + '*.asc') for date in re.findall(\"(\\d{10})\", file)]\n",
    "date = [date for file in glob.glob(save_dir + '*.asc') for date in re.findall(\"(\\d{10})\", file)]\n",
    "date.sort(key = lambda date: datetime.strptime(date, \"%Y%m%d%H\")) \n",
    "delt = datetime.strptime(date[1], \"%Y%m%d%H\") - datetime.strptime(date[0], \"%Y%m%d%H\")\n",
    "# AscFiles = glob.glob(inDir + '*.asc')\n",
    "AscFiles = glob.glob(save_dir + '*.asc')\n",
    "\n",
    "for index in range(0, len(date)):\n",
    "\n",
    "    namefile = 'MSWEP.' + date[index] + '.asc'\n",
    "    objDate = datetime.strptime(date[index], '%Y%m%d%H')\n",
    "\n",
    "    if (objDate.hour==0): \n",
    "        objDate0 = objDate - delt #timedelta(hours=1)\n",
    "        objDate = objDate - delt #timedelta(days=1)\n",
    "        converted_date = datetime.strftime(objDate,'%d%b%Y:2400') #HEC-DSS only accept 24:00 format!\n",
    "    else:\n",
    "        converted_date = datetime.strftime(objDate,'%d%b%Y:%H%M')\n",
    "        objDate0 = objDate - delt#timedelta(hours=1)\n",
    "    \n",
    "    converted_date0 = datetime.strftime(objDate0,'%d%b%Y:%H%M')\n",
    "\n",
    "    full_text = text_1 + namefile + text_2 + converted_date0 + text_3 + converted_date + text_4\n",
    "    file1.write(full_text + \"\\n\")\n",
    "    \n",
    "file1.close() #to close file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-flood01_win10] *",
   "language": "python",
   "name": "conda-env-.conda-flood01_win10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
